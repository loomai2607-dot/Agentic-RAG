ğŸ§  Agentic RAG with AutoGen + LangGraph + Pinecone

An Agentic Retrieval-Augmented Generation (RAG) system that combines:

AutoGen + LangGraph for agent orchestration and workflow management

Pinecone for vector storage and semantic retrieval

Groq LLMs for fast reasoning and generation

Full traceability of agent workflows for transparency and observability

This repo includes both backend (FastAPI) and frontend (React) implementations, with a professional UI for real-time query flow and agent trace visualization.

âœ¨ Features

âš¡ Agentic Orchestration: Multi-agent workflow powered by AutoGen and LangGraph

ğŸ“š Knowledge Retrieval: Scalable Pinecone vector database for embeddings and semantic search

ğŸ§  LLM Integration: Groq APIs for embeddings + text generation (low latency)

ğŸ” Traceability & Observability:

LangGraph trace visualization of each agent step

Custom trace logger hooks for reliable observability

ğŸ“„ Dynamic Document Ingestion: Upload and embed PDFs into Pinecone in real-time

ğŸ’¬ Chat Interface: React-based UI for querying the system and exploring results

ğŸ¨ Professional Frontend: Polished React UI with query flow, chat history, and trace canvas

ğŸ“‚ Repo Structure
RAG/
â”œâ”€â”€ backend/                # FastAPI backend
â”‚   â”œâ”€â”€ main.py             # Entry point
â”‚   â”œâ”€â”€ routes/             # API endpoints (upload, query, embed, etc.)
â”‚   â”œâ”€â”€ services/           # Embedding, retrieval, and generation services
â”‚   â”œâ”€â”€ agents/             # AutoGen + LangGraph agent workflows
â”‚   â”œâ”€â”€ utils/              # Trace logger + observability utilities
â”‚   â””â”€â”€ config/             # Env and settings
â”‚
â”œâ”€â”€ frontend/               # React + TypeScript frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # Chat, trace viewer, uploader
â”‚   â”‚   â”œâ”€â”€ pages/          # Main UI pages
â”‚   â”‚   â”œâ”€â”€ store/          # Redux state management
â”‚   â”‚   â”œâ”€â”€ api/            # API integration layer
â”‚   â”‚   â””â”€â”€ App.tsx
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ docs/                   # Documentation, diagrams, architecture
â””â”€â”€ README.md               # This file

ğŸš€ Getting Started
1ï¸âƒ£ Clone the repo
git clone https://github.com/your-username/agentic-rag.git
cd agentic-rag

2ï¸âƒ£ Backend Setup
cd backend
python -m venv venv
source venv/bin/activate   # (Windows: venv\Scripts\activate)
pip install -r requirements.txt


Create a .env file in backend/ with:

PINECONE_API_KEY=your_pinecone_key
GROQ_API_KEY=your_groq_key
PINECONE_ENV=your_env


Run the backend:

uvicorn main:app --reload --port 8000

3ï¸âƒ£ Frontend Setup
cd frontend
npm install
npm start


The app will be available at http://localhost:3000

ğŸ” Usage

Upload a PDF â†’ itâ€™s embedded into Pinecone

Ask a question â†’ retrieval happens via Pinecone

Groq LLM generates contextual answers

LangGraph trace viewer shows the full agent workflow (retrieval â†’ reasoning â†’ generation)

ğŸ“Š Observability

âœ… Agent workflow traces are captured and visualized in the frontend
âœ… Custom trace logger ensures logs are persistent for debugging & analytics
âœ… Real-time view of query flow for explainability

ğŸ›  Tech Stack

Backend: FastAPI, AutoGen, LangGraph, Pinecone, Groq

Frontend: React, TypeScript, Redux, Material UI, d3/graph visualization

Infra: Modular, extensible, designed for production-ready RAG pipelines